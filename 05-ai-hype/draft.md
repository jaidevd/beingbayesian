> It is said that to explain is to explain away. This maxim is nowhere so well
> fulfilled as in the area of computer programming, especially in what is ealled
> heuristic programming and artifieiM intelligence. For in those realms machines
> are made to behave in wondrous ways, often suftieient to dazzle even the most
> experim~eed observer. But once a particular program is unmasked, once its inner
> workings are explained in language sufficiently plain to induce understanding,
> its magic crumbles away...

- Joseph Weizenbaum

![](https://obamawhitehouse.archives.gov/sites/default/files/imagecache/gallery_img_full/image/image_file/42.jpg?itok=bdBOhLvF)

Most of us would think that this picture is funny. We'd come to this realization
at a glance, in no more than a second. And if we were to carefully unravel our
chain of thought behind this reaction, we'd end up with something like this:

* We detect that there are people in the picture
* We see that there's someone standing on a weighing scale. We know, further,
  what weighing scales do.
* We notice that someone is pressing down on the scale, unbeknowst to the person
  standing on it.
* We know how scales work, and we know that most people are conscious of their
  weight, and so we infer that someone is playing a prank.
* We further realzie that the person playing a prank isn't just anyone - he's
  one of the most powerful men in the world. It's made funnier by our collective
  cultural belief that leaders are supposed to be dignified.

That, in short, is the sort of reasoning it takes to comprehend a picture.

Now, when I paste the image into ChatGPT (try it out!) and ask it why it's
funny, here's what it says:

> This picture is funny because it captures a playful moment: a man is standing
> on a scale, and another man (in a suit) is humorously stepping on it, likely
> to make the weight reading higher. The lighthearted teasing, unexpected in a
> formal setting with suits and officials around, makes the scene amusing.

While not as nuanced as the earlier explanation, this is still not bad at all.

I first heard the example above in a lecture by Justin Johnson from a computer
vision course in Stanford University, which in turn was borrowed from a blog
post by Andrej Karpathy - a noted AI researcher.

I've been training machines to see, read and write for 15 years now - since well
before it was cool. I've become jaded, and I suffer from what Steven Pinker
calls the "curse of knowledge". Being intimately familiar with the inner
mechanism of these systems, I'm usually unimpressed (why, really? because you
know that all they're doing is scaling - there's no _real_ innovation going on -
has this out). That's made me cynical. And I therefore become frightfully mad
when people think AI is going to solve all our problems.
