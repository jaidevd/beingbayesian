The idea of thinking machines and anthropmorphized automatons in mythology and
fiction dates back to antiquity. Cultivating some form of intelligence in a
mechanical, automatic, controllable object has captured humanity's imagination
for as long as we can remember. This impulse persists across ages and cultures,
like the search for meaning or the urge to control and master. The pursuit of
artificial intelligence is in some ways a spiritual pursuit—an exploration of
what it means to be intelligent, to be human[^1]. A programmer who sees their
machines learn how to see, write and read for the first time feels like
Hephaestus creating Pandora. Algorithms become alchemy. It's only natural that
we love it.

In the last few decades, AI has become an umbrella term, referring to a broad set of
technologies and methods. But in it's current usage in the media, "AI" refers
almost exclusively to _generative_ AI - stuff that learns from patterns in
language, vision and speech to generate human-like content. Generative AI itself
is a specialized application of a paradigm known as artificial neural
networks—algorithms that use a collection of artificial neurons, which in turn
are inspired by biological neurons. The artificial neuron was first proposed 80
years ago—by neuroscientist Warren McCulloch and logician Walter Pitts. The
history of hype in AI is almost as old as the artificial neuron, as we shall
see.

A biological neuron, or a nerve cell, has dendrites, axons and a soma; which
respectively perform the functions of input stimuli, output stimuli and an
aggregation process on the inputs.


[^1]: Mark Rowlands on the endless pursuit to figure out what separates humans
    from animals.
